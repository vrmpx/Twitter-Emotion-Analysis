{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedings\n",
    "\n",
    "Define sentence iterator. \n",
    "Perform pre-processing:\n",
    "0. Lowercase & tokenize\n",
    "1. Replace @MENTION & URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train embeddings in sentences using Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "class MySentences(object):\n",
    "    def __init__(self, dirname, fname):\n",
    "        self.dirname = dirname\n",
    "        self.fname = fname\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for line in open(os.path.join(self.dirname, self.fname)):\n",
    "            yield line.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = MySentences('../data/SentimentCorpus/', 'es.tsv.neg.lower.preprocessed')\n",
    "model = gensim.models.Word2Vec(sentences, size=400, alpha=0.025, window=5, min_count=5, max_vocab_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('../data/SentimentCorpus/es.word2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.most_similar(positive=['hombre'], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.most_similar(positive=['mujer'], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.most_similar(positive=['apple'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = MySentences('../data/SentimentCorpus/', 'en.tsv.neg.lower.preprocessed')\n",
    "model = gensim.models.Word2Vec(sentences, size=400, alpha=0.025, window=5, min_count=5, max_vocab_size=None)\n",
    "model.save('../data/en.word2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.most_similar(positive=['man'], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.most_similar(positive=['woman'], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.most_similar(positive=['samsung', 'smartphone'], negative=['phone'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expand ANEW and ANSW\n",
    "Spanish:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "es_model = gensim.models.Word2Vec.load('../data/Word2Vec/es.word2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "answ = pd.read_csv('../data/SentimentCorpus/ANEW/ANSW.tsv', sep = '\\t')\n",
    "print len(answ)\n",
    "answ.sort_values(by = 'Val-Mn-All').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "answ.Freq = answ.Freq.fillna(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "\n",
    "for idx, row in answ.iterrows():\n",
    "    try:\n",
    "        sims = es_model.most_similar(positive = [row['S-Word']], topn = 100)\n",
    "    except:\n",
    "        sims = []\n",
    "        \n",
    "    for sim, weight in filter(lambda x: x[1] > 0.5, sims):\n",
    "        r = {}\n",
    "        r['word'] = sim\n",
    "        for c in [u'Val-Mn-All', u'Val-Sd-All', u'Aro-Mn-All', u'Aro-Sd-All', 'Freq']:\n",
    "            r[c] = row[c] * weight\n",
    "            \n",
    "        res.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = pd.DataFrame(res)\n",
    "print len(res)\n",
    "res.sort_values(by='Val-Mn-All').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat original ANSW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "original = answ[['Aro-Mn-All', 'Aro-Sd-All', 'Val-Mn-All', 'Val-Sd-All', 'Freq', 'S-Word']]\n",
    "original.columns = ['Aro-Mn-All','Aro-Sd-All', 'Val-Mn-All', 'Val-Sd-All', 'Freq', 'word']\n",
    "tmp = pd.concat([res, original])\n",
    "print len(tmp)\n",
    "tmp.sort_values(by='Val-Mn-All').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compress & Remove Dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = tmp\n",
    "res2 = defaultdict(list)\n",
    "for idx, row in res.iterrows():\n",
    "    res2[row['word']].append((float(row['Val-Mn-All']), float(row['Val-Sd-All']),\n",
    "                              float(row['Aro-Mn-All']), float(row['Aro-Sd-All']),\n",
    "                              float(row['Freq'])))\n",
    "    \n",
    "tmp = {'Valence': {}, 'Valence.std': {}, 'Arousal':{}, 'Arousal.std':{}, 'Frequency':{}}\n",
    "for k, tlist in res2.iteritems():\n",
    "    average_tuple = tuple(map(lambda y: sum(y) / float(len(y)), zip(*tlist)))\n",
    "    tmp['Valence'][k] = average_tuple[0]\n",
    "    tmp['Valence.std'][k] = average_tuple[1]\n",
    "    tmp['Arousal'][k] = average_tuple[2]\n",
    "    tmp['Arousal.std'][k] = average_tuple[3]\n",
    "    tmp['Frequency'][k] = average_tuple[4]\n",
    "    \n",
    "tmp = pd.DataFrame(tmp)\n",
    "tmp.sort_values(by = 'Valence').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp.Frequency.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = tmp\n",
    "print len(res)\n",
    "res.to_csv('../data/expandedANSW.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "es_model = None\n",
    "res = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### __English:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "en_model = gensim.models.Word2Vec.load('../data/Word2Vec/en.word2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "anew = pd.read_csv('../data/SentimentCorpus/ANEW/anew_list.csv')\n",
    "anew.sort_values(by='Valence').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anew.Frequency = anew.Frequency.fillna(1) #Not so good Turing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "\n",
    "for idx, row in anew.iterrows():\n",
    "    try:\n",
    "        sims = en_model.most_similar(positive = [row['Description']], topn = 100)\n",
    "    except:\n",
    "        sims = []\n",
    "        \n",
    "    for sim, weight in filter(lambda x: x[1] > 0.5, sims):\n",
    "        r = {}\n",
    "        r['word'] = sim\n",
    "        for c in [ u'Valence', u'std', u'Arousal', u'std.1', 'Frequency']:\n",
    "            r[c] = row[c] * weight\n",
    "            \n",
    "        res.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = pd.DataFrame(res)\n",
    "print len(res)\n",
    "res.sort_values(by='Valence').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res[(res.word == 'terrorists')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat original ANEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "original = anew[['Arousal','std.1', 'Valence', 'std', 'Frequency' ,'Description']]\n",
    "original.columns = ['Arousal', 'std.1', 'Valence', 'std', 'Frequency', 'word']\n",
    "tmp = pd.concat([res, original])\n",
    "print len(tmp)\n",
    "tmp.sort_values(by='Valence').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = tmp\n",
    "res2 = defaultdict(list)\n",
    "for idx, row in res.iterrows():\n",
    "    res2[row['word']].append((float(row['Valence']), float(row['std']),\n",
    "                              float(row['Arousal']), float(row['std.1']),\n",
    "                              float(row['Frequency'])))\n",
    "    \n",
    "tmp = {'Valence': {}, 'Valence.std': {}, 'Arousal':{}, 'Arousal.std':{}, 'Frequency':{}}\n",
    "for k, tlist in res2.iteritems():\n",
    "    average_tuple = tuple(map(lambda y: sum(y) / float(len(y)), zip(*tlist)))\n",
    "    tmp['Valence'][k] = average_tuple[0]\n",
    "    tmp['Valence.std'][k] = average_tuple[1]\n",
    "    tmp['Arousal'][k] = average_tuple[2]\n",
    "    tmp['Arousal.std'][k] = average_tuple[3]\n",
    "    tmp['Frequency'][k] = average_tuple[4]\n",
    "    \n",
    "res = pd.DataFrame(tmp)\n",
    "print len(res)\n",
    "res.sort_values(by = 'Valence').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res.ix['terrorists']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res.to_csv('../data/expandedANEW.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
